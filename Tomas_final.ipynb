{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "### Practical Session\n",
    "\n",
    "<br/> Prof. Dr. Georgios K. Ouzounis\n",
    "<br/> email: georgios.ouzounis@go.kauko.lt\n",
    "\n",
    "<br/> Student Tomas Radžiūnas\n",
    "<br/> email: tomas.ra9418@go.kauko.lt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. Data loading and pre-processing\n",
    "2. Building the RNN\n",
    "3. Train and deploy the RNN\n",
    "4. Improving the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a 10-year history of the Microsoft Stock prices, we are going to predict the stock values for the most recent month that is not included in the historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data-sets\n",
    "\n",
    "The data-sets are two comma-separated values files (CSV) and contain a data table of 2538 records for training and a table of 22 records for testing.\n",
    "\n",
    "We download these from finance.yahoo.com and then upload them to our github repository.\n",
    "\n",
    "**Microsoft_Stock_Price_Test.csv** and **Microsoft_Stock_Price_Train.csv**\n",
    "\n",
    "We then download them using the wget command in the terminal\n",
    "\n",
    "```shell\n",
    "wget https://raw.githubusercontent.com/Eimantas1337/assignment/main/Microsoft_Stock_Price_Test.csv\n",
    "\n",
    "wget https://raw.githubusercontent.com/Eimantas1337/assignment/main/Microsoft_Stock_Price_Train.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "We need 3 main libraries:\n",
    "\n",
    "- [Numpy](http://www.numpy.org): it is the fundamental package for scientific computing with Python. It contains among other things a powerful N-dimensional array object that can be used as an efficient multi-dimensional container of generic data. Arbitrary data-types can be defined.\n",
    "- [matplotlib](https://matplotlib.org):  it is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.\n",
    "- [pandas](https://pandas.pydata.org): is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the relevant files containing 10 years of stock prices of Microsoft from 2009 to 2019.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "\n",
    "# load the training file contents \n",
    "dataset_train = pd.read_csv('Microsoft_Stock_Price_Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-07-01</td>\n",
       "      <td>24.049999</td>\n",
       "      <td>24.299999</td>\n",
       "      <td>23.959999</td>\n",
       "      <td>24.040001</td>\n",
       "      <td>18.585423</td>\n",
       "      <td>54908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-02</td>\n",
       "      <td>23.760000</td>\n",
       "      <td>24.040001</td>\n",
       "      <td>23.209999</td>\n",
       "      <td>23.370001</td>\n",
       "      <td>18.067444</td>\n",
       "      <td>65422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-07-06</td>\n",
       "      <td>23.209999</td>\n",
       "      <td>23.280001</td>\n",
       "      <td>22.870001</td>\n",
       "      <td>23.200001</td>\n",
       "      <td>17.936018</td>\n",
       "      <td>49207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-07-07</td>\n",
       "      <td>23.080000</td>\n",
       "      <td>23.139999</td>\n",
       "      <td>22.459999</td>\n",
       "      <td>22.530001</td>\n",
       "      <td>17.418032</td>\n",
       "      <td>52842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-07-08</td>\n",
       "      <td>22.309999</td>\n",
       "      <td>22.690001</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.559999</td>\n",
       "      <td>17.441227</td>\n",
       "      <td>73023400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2009-07-01  24.049999  24.299999  23.959999  24.040001  18.585423  54908400\n",
       "1  2009-07-02  23.760000  24.040001  23.209999  23.370001  18.067444  65422200\n",
       "2  2009-07-06  23.209999  23.280001  22.870001  23.200001  17.936018  49207700\n",
       "3  2009-07-07  23.080000  23.139999  22.459999  22.530001  17.418032  52842500\n",
       "4  2009-07-08  22.309999  22.690001  22.000000  22.559999  17.441227  73023400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subtable of relevant entries (open values)\n",
    "# The .values makes this vector a numpy array\n",
    "training_set = dataset_train.iloc[:, 1:2].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 24.049999],\n",
       "       [ 23.76    ],\n",
       "       [ 23.209999],\n",
       "       ...,\n",
       "       [140.369995],\n",
       "       [141.5     ],\n",
       "       [140.139999]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Next we need to rescale our data to the range from 0 to 1. \n",
    "\n",
    "Feature scaling is essential as discussed if the Features lecture and needs to be applied to both the training and test sets.\n",
    "\n",
    "It is computed using the ScikitLearn library [MinMaxScaler()](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) which transforms the selected feature by scaling it to a given range. If more than one, this estimator scales and translates each feature individually such that it is in the given range on the training set, i.e. between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "# import the MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scaler instance to rescale all data to the range of 0.0 to 1.0 \n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the actual training set of scaled values\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01558962],\n",
       "       [0.01315899],\n",
       "       [0.00854914],\n",
       "       ...,\n",
       "       [0.99052883],\n",
       "       [1.        ],\n",
       "       [0.98860111]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the training set to dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data structure with 90 timesteps and 1 output\n",
    "\n",
    "# the 90 stock prices in the last 3 months before today\n",
    "X_train = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2537, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the stock price today\n",
    "y_train = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start from day 90 because that is the first instance allowing us to \n",
    "# go back 90 days. we also change the range to 2537, because we have 2537 records in our 10 year dataset\n",
    "for i in range(90, 2537): \n",
    "    # 0 is the column ID, the only column in this case.    \n",
    "    # put the last 90 days values in one row of X_train\n",
    "    X_train.append(training_set_scaled[i-90:i, 0]) \n",
    "    y_train.append(training_set_scaled[i, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01558962, 0.01315899, 0.00854914, ..., 0.04567931, 0.0460984 ,\n",
       "        0.05305506],\n",
       "       [0.01315899, 0.00854914, 0.00745955, ..., 0.0460984 , 0.05305506,\n",
       "        0.05188164],\n",
       "       [0.00854914, 0.00745955, 0.00100577, ..., 0.05305506, 0.05188164,\n",
       "        0.05389322],\n",
       "       ...,\n",
       "       [0.80378842, 0.79792137, 0.79582599, ..., 0.9854161 , 0.97820798,\n",
       "        0.99103171],\n",
       "       [0.79792137, 0.79582599, 0.8156064 , ..., 0.97820798, 0.99103171,\n",
       "        0.99052883],\n",
       "       [0.79582599, 0.8156064 , 0.7909647 , ..., 0.99103171, 0.99052883,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the Matrix\n",
    "\n",
    "We need to add a new matrix dimension to accommodate the indicator (predictor). \n",
    "\n",
    "NumPy matrices are tensors (3D) and essentially we need to specify that our matrix consists of **90 days** (dimension x) times **total days in data set** (dimension y) times **1 value per matrix cell (scalar)** (dimension z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data matrix, we retain the 2 original dimensions and add a third of depth=1\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading keras and initializing the RNN\n",
    "\n",
    "We put <b>pip3 install keras</b> in our terminal to download keras for this task.\n",
    "\n",
    "Using Keras, that we installed earlier, we are going to import the sequential model, dense layer template and the LTSM model from the Keras API and we are going to create an instance of the sequential model called regressor because we want to predict a continious value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the RNN as a sequence of layers\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add First Layer\n",
    "\n",
    "We first add an object of the LSTM class! \n",
    "\n",
    "- The first argument is the number of units or LSTM memory cells. Include many neurons to address the high dimensionality of the problem; say 50 neurons! \n",
    "- Second arg: return sequences = true; stacked LSTM !\n",
    "- Third arg: input 3D shape: observations vs time steps vs number of indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the LSTM layer\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape =  (X_train.shape[1], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the argument is the dropout rate to ignore in the layers (20%), \n",
    "# i.e. 50 units * 20% = 10 units will be dropped each time\n",
    "regressor.add(Dropout(0.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add More Layers\n",
    "\n",
    "We can add more LSTM layers but along with Dropout regularization to make sure we avoid overfitting! \n",
    "\n",
    "We don’t need to add the shape of the layer again because it is recognized automatically from the number of input units.\n",
    "\n",
    "The last layer does not return a sequence but connected directly to a fully connected output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "# we removed the return_sequences because we no longer return a \n",
    "# sequence but a value instead\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Output Layer & Compile\n",
    "\n",
    "The output has 1 dimension , i.e. one value to be predicted thus or output fully connected layer has dimensionality = 1.\n",
    "\n",
    "- **Optimizer**: rmsprop is recommended in the Keras documentation. The Adam optimizer is also a powerful choice.\n",
    "- **Loss function**: regression problems take the mean square error as most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and deploy the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the RNN to the Training set\n",
    "\n",
    "Now we train our RNN using the data in our training set and ground truth. We also have a couple of parameters that we could specify:\n",
    "\n",
    "- **Batch size**:  update the cell weights not on every stock price on every batch_size values; \n",
    "- **Number of epochs**: how many iterations to be used, i.e. number of forward and backward propagations for the update of the weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 [==============================] - 10s 130ms/step - loss: 0.0092\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 0.0017\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0016\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0013\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0012\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0017\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 10s 124ms/step - loss: 0.0015\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0011\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0013\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0012\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0014\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0012\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 10s 125ms/step - loss: 0.0010\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 10s 130ms/step - loss: 0.0011\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 10s 135ms/step - loss: 0.0012\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 12s 162ms/step - loss: 8.9236e-04\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 11s 143ms/step - loss: 0.0012\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 0.0010\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 10s 126ms/step - loss: 0.0012\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 11s 141ms/step - loss: 9.1363e-04\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 10s 135ms/step - loss: 9.2280e-04\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 10s 127ms/step - loss: 8.8396e-04\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 10s 133ms/step - loss: 9.0922e-04\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 10s 133ms/step - loss: 0.0010\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 11s 141ms/step - loss: 9.5842e-04\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 14s 185ms/step - loss: 9.0868e-04\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 11s 149ms/step - loss: 9.9790e-04\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 14s 183ms/step - loss: 8.9825e-04\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 13s 170ms/step - loss: 8.9491e-04\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 12s 155ms/step - loss: 9.1186e-04\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 12s 158ms/step - loss: 8.7660e-04\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 11s 149ms/step - loss: 8.4982e-04\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 11s 147ms/step - loss: 7.9162e-04\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 12s 151ms/step - loss: 8.0643e-04\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 11s 139ms/step - loss: 8.9313e-04\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 7.5318e-04\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 12s 150ms/step - loss: 0.0011\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 12s 151ms/step - loss: 8.1611e-04\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 11s 143ms/step - loss: 7.4611e-04\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 12s 156ms/step - loss: 7.9589e-04\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 12s 162ms/step - loss: 8.0000e-04\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 12s 151ms/step - loss: 8.0916e-04\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 11s 145ms/step - loss: 6.8288e-04\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 12s 150ms/step - loss: 7.8040e-04\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 12s 157ms/step - loss: 7.2974e-04\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 12s 151ms/step - loss: 7.8862e-04\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 12s 152ms/step - loss: 6.9146e-04\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 11s 141ms/step - loss: 7.5773e-04\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 11s 145ms/step - loss: 7.8827e-04\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 11s 142ms/step - loss: 7.2037e-04\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 12s 150ms/step - loss: 7.0374e-04\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 11s 148ms/step - loss: 7.3460e-04\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 12s 153ms/step - loss: 7.1720e-04\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 12s 156ms/step - loss: 7.2549e-04\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 11s 147ms/step - loss: 6.8460e-04\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 12s 160ms/step - loss: 6.7627e-04\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 12s 153ms/step - loss: 6.8658e-04\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 11s 147ms/step - loss: 6.5884e-04\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 11s 147ms/step - loss: 6.6599e-04\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 11s 145ms/step - loss: 5.8598e-04\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 11s 142ms/step - loss: 6.4294e-04\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 12s 161ms/step - loss: 8.0911e-04\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 12s 153ms/step - loss: 6.7155e-04\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 12s 150ms/step - loss: 6.6390e-04\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 6.6962e-04\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 10s 130ms/step - loss: 6.9623e-04\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 10s 134ms/step - loss: 6.1358e-04\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 10s 134ms/step - loss: 6.4257e-04\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 12s 152ms/step - loss: 7.6365e-04\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 11s 147ms/step - loss: 7.8964e-04\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 12s 157ms/step - loss: 6.3537e-04\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 11s 144ms/step - loss: 5.7473e-04\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 6.2303e-04\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 11s 149ms/step - loss: 7.8176e-04\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 11s 149ms/step - loss: 7.9283e-04\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 12s 153ms/step - loss: 6.5585e-04\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 5.7694e-04\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 11s 137ms/step - loss: 6.5783e-04\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 11s 145ms/step - loss: 6.2304e-04\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 5.7418e-04\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 11s 141ms/step - loss: 6.3082e-04\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 11s 142ms/step - loss: 6.0988e-04\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 11s 140ms/step - loss: 6.3994e-04\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 12s 153ms/step - loss: 6.7512e-04\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 11s 139ms/step - loss: 7.1666e-04\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 11s 148ms/step - loss: 6.0645e-04\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 12s 150ms/step - loss: 6.6551e-04\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 5.7000e-04\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 11s 147ms/step - loss: 5.8380e-04\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 6.1939e-04\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 11s 140ms/step - loss: 6.3811e-04\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 11s 138ms/step - loss: 7.0052e-04\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 11s 140ms/step - loss: 6.3099e-04\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 12s 156ms/step - loss: 6.1525e-04\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 12s 150ms/step - loss: 5.6833e-04\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 11s 139ms/step - loss: 6.7665e-04\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 12s 154ms/step - loss: 6.0569e-04\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 11s 146ms/step - loss: 5.0629e-04\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 11s 142ms/step - loss: 5.4657e-04\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 11s 144ms/step - loss: 5.2319e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f71802456d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Predictions\n",
    "\n",
    "Now I create a data-frame by impoting the Microsoft Stock Price Test set for August 2019 using pandas and I make it a numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>140.940002</td>\n",
       "      <td>136.929993</td>\n",
       "      <td>138.059998</td>\n",
       "      <td>136.052872</td>\n",
       "      <td>40557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>138.089996</td>\n",
       "      <td>138.320007</td>\n",
       "      <td>135.259995</td>\n",
       "      <td>136.899994</td>\n",
       "      <td>134.909729</td>\n",
       "      <td>30791600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>133.300003</td>\n",
       "      <td>133.929993</td>\n",
       "      <td>130.779999</td>\n",
       "      <td>132.210007</td>\n",
       "      <td>130.287949</td>\n",
       "      <td>42749600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>133.800003</td>\n",
       "      <td>135.679993</td>\n",
       "      <td>133.210007</td>\n",
       "      <td>134.690002</td>\n",
       "      <td>132.731888</td>\n",
       "      <td>32696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>133.789993</td>\n",
       "      <td>135.649994</td>\n",
       "      <td>131.830002</td>\n",
       "      <td>135.279999</td>\n",
       "      <td>133.313278</td>\n",
       "      <td>33414500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>136.600006</td>\n",
       "      <td>138.990005</td>\n",
       "      <td>135.929993</td>\n",
       "      <td>138.889999</td>\n",
       "      <td>136.870834</td>\n",
       "      <td>27496500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>138.610001</td>\n",
       "      <td>139.380005</td>\n",
       "      <td>136.460007</td>\n",
       "      <td>137.710007</td>\n",
       "      <td>135.707993</td>\n",
       "      <td>23466700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>137.070007</td>\n",
       "      <td>137.860001</td>\n",
       "      <td>135.240005</td>\n",
       "      <td>135.789993</td>\n",
       "      <td>133.815887</td>\n",
       "      <td>20476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>136.050003</td>\n",
       "      <td>138.800003</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>138.600006</td>\n",
       "      <td>136.585052</td>\n",
       "      <td>25154600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>136.360001</td>\n",
       "      <td>136.919998</td>\n",
       "      <td>133.669998</td>\n",
       "      <td>133.979996</td>\n",
       "      <td>132.471863</td>\n",
       "      <td>32527300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>134.389999</td>\n",
       "      <td>134.580002</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>133.679993</td>\n",
       "      <td>132.175247</td>\n",
       "      <td>28074400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>134.880005</td>\n",
       "      <td>136.460007</td>\n",
       "      <td>134.720001</td>\n",
       "      <td>136.130005</td>\n",
       "      <td>134.597687</td>\n",
       "      <td>24449100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>137.850006</td>\n",
       "      <td>138.550003</td>\n",
       "      <td>136.889999</td>\n",
       "      <td>138.410004</td>\n",
       "      <td>136.852020</td>\n",
       "      <td>24355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>138.210007</td>\n",
       "      <td>138.710007</td>\n",
       "      <td>137.240005</td>\n",
       "      <td>137.259995</td>\n",
       "      <td>135.714951</td>\n",
       "      <td>21170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>138.550003</td>\n",
       "      <td>139.490005</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>138.789993</td>\n",
       "      <td>137.227707</td>\n",
       "      <td>14970300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>138.660004</td>\n",
       "      <td>139.199997</td>\n",
       "      <td>136.289993</td>\n",
       "      <td>137.779999</td>\n",
       "      <td>136.229080</td>\n",
       "      <td>18697000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>137.190002</td>\n",
       "      <td>138.350006</td>\n",
       "      <td>132.800003</td>\n",
       "      <td>133.389999</td>\n",
       "      <td>131.888504</td>\n",
       "      <td>38508600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>134.990005</td>\n",
       "      <td>135.559998</td>\n",
       "      <td>133.899994</td>\n",
       "      <td>135.449997</td>\n",
       "      <td>133.925323</td>\n",
       "      <td>20312600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>136.389999</td>\n",
       "      <td>136.720001</td>\n",
       "      <td>134.660004</td>\n",
       "      <td>135.740005</td>\n",
       "      <td>134.212051</td>\n",
       "      <td>23102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>134.880005</td>\n",
       "      <td>135.759995</td>\n",
       "      <td>133.550003</td>\n",
       "      <td>135.559998</td>\n",
       "      <td>134.034073</td>\n",
       "      <td>17393300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>137.250000</td>\n",
       "      <td>138.440002</td>\n",
       "      <td>136.910004</td>\n",
       "      <td>138.119995</td>\n",
       "      <td>136.565262</td>\n",
       "      <td>20168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>139.149994</td>\n",
       "      <td>139.179993</td>\n",
       "      <td>136.270004</td>\n",
       "      <td>137.860001</td>\n",
       "      <td>136.308212</td>\n",
       "      <td>23940100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Open        High         Low       Close   Adj Close  \\\n",
       "0   2019-08-01  137.000000  140.940002  136.929993  138.059998  136.052872   \n",
       "1   2019-08-02  138.089996  138.320007  135.259995  136.899994  134.909729   \n",
       "2   2019-08-05  133.300003  133.929993  130.779999  132.210007  130.287949   \n",
       "3   2019-08-06  133.800003  135.679993  133.210007  134.690002  132.731888   \n",
       "4   2019-08-07  133.789993  135.649994  131.830002  135.279999  133.313278   \n",
       "5   2019-08-08  136.600006  138.990005  135.929993  138.889999  136.870834   \n",
       "6   2019-08-09  138.610001  139.380005  136.460007  137.710007  135.707993   \n",
       "7   2019-08-12  137.070007  137.860001  135.240005  135.789993  133.815887   \n",
       "8   2019-08-13  136.050003  138.800003  135.000000  138.600006  136.585052   \n",
       "9   2019-08-14  136.360001  136.919998  133.669998  133.979996  132.471863   \n",
       "10  2019-08-15  134.389999  134.580002  132.250000  133.679993  132.175247   \n",
       "11  2019-08-16  134.880005  136.460007  134.720001  136.130005  134.597687   \n",
       "12  2019-08-19  137.850006  138.550003  136.889999  138.410004  136.852020   \n",
       "13  2019-08-20  138.210007  138.710007  137.240005  137.259995  135.714951   \n",
       "14  2019-08-21  138.550003  139.490005  138.000000  138.789993  137.227707   \n",
       "15  2019-08-22  138.660004  139.199997  136.289993  137.779999  136.229080   \n",
       "16  2019-08-23  137.190002  138.350006  132.800003  133.389999  131.888504   \n",
       "17  2019-08-26  134.990005  135.559998  133.899994  135.449997  133.925323   \n",
       "18  2019-08-27  136.389999  136.720001  134.660004  135.740005  134.212051   \n",
       "19  2019-08-28  134.880005  135.759995  133.550003  135.559998  134.034073   \n",
       "20  2019-08-29  137.250000  138.440002  136.910004  138.119995  136.565262   \n",
       "21  2019-08-30  139.149994  139.179993  136.270004  137.860001  136.308212   \n",
       "\n",
       "      Volume  \n",
       "0   40557500  \n",
       "1   30791600  \n",
       "2   42749600  \n",
       "3   32696700  \n",
       "4   33414500  \n",
       "5   27496500  \n",
       "6   23466700  \n",
       "7   20476600  \n",
       "8   25154600  \n",
       "9   32527300  \n",
       "10  28074400  \n",
       "11  24449100  \n",
       "12  24355700  \n",
       "13  21170800  \n",
       "14  14970300  \n",
       "15  18697000  \n",
       "16  38508600  \n",
       "17  20312600  \n",
       "18  23102100  \n",
       "19  17393300  \n",
       "20  20168700  \n",
       "21  23940100  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the real stock price for July 31st 2009 - \n",
    "# July 31st 2019\n",
    "dataset_test = pd.read_csv('Microsoft_Stock_Price_Test.csv')\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "real_stock_price.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137.      ],\n",
       "       [138.089996],\n",
       "       [133.300003],\n",
       "       [133.800003],\n",
       "       [133.789993],\n",
       "       [136.600006],\n",
       "       [138.610001],\n",
       "       [137.070007],\n",
       "       [136.050003],\n",
       "       [136.360001],\n",
       "       [134.389999],\n",
       "       [134.880005],\n",
       "       [137.850006],\n",
       "       [138.210007],\n",
       "       [138.550003],\n",
       "       [138.660004],\n",
       "       [137.190002],\n",
       "       [134.990005],\n",
       "       [136.389999],\n",
       "       [134.880005],\n",
       "       [137.25    ],\n",
       "       [139.149994]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2019\n",
    "\n",
    "# axis = 0 means concatenate the lines (i.e. vertical axis)\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2559"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_total.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the difference in the length of the first two gives us \n",
    "# the first day in 2019, and we need to go back 90 days to get the necessary range\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 90:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we did not use iloc from panda so lets reshape the numpy array for \n",
    "# compatibility: i.e. all the values from input lines to be stacked in one \n",
    "# column. The -1 means that the numpy has no knowledge of how the \n",
    "# values were stored in lines. The 1 means we want to them in one \n",
    "# column.\n",
    "\n",
    "inputs = inputs.reshape(-1,1) \n",
    "\n",
    "# apply the feature scaler\n",
    "inputs = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2019\n",
    "X_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first 90 from inputs are from training set; start \n",
    "# from 90 and get the extra 22\n",
    "for i in range(90, 112): \n",
    "    X_test.append(inputs[i-90:i, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test) # not 3D structure yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 3D structure\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to inverse the scaling to get meaningful predicted stock price # outputs\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price) \n",
    "predicted_stock_price.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Microsoft Stock Price')\n",
    "\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Microsoft Stock Price')\n",
    "\n",
    "plt.title('Microsoft Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Microsoft Stock Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue line shows the trend of the stock for the month of August 2019. \n",
    "\n",
    "Some observations:\n",
    "- The prediction is far more smoother than the actual stock price.\n",
    "- Some fiddling is required to get a smaller relative error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the RMSE\n",
    "\n",
    "If we need to compute the RMSE for our Stock Price Prediction problerm, we use the real stock rpice and predicted stock price as shown.\n",
    "\n",
    "We can getting a relative error, by dividing this RMSE by the range of the Microsoft Stock Price values of August 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.248572859963501"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = math.sqrt( mean_squared_error( real_stock_price[0:22,:], predicted_stock_price))\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
